{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Twitter_Trends_Classifier.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "israeli-whole"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tweepy as tw\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy.streaming import StreamListener\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import collections\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import time\n",
        "import json\n",
        "import sys\n",
        "from datetime import datetime"
      ],
      "id": "israeli-whole",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sealed-colon"
      },
      "source": [
        "consumer_key = \"xuSrX6LK9gfsWnJ1CTQblfL83\"\n",
        "consumer_secret = \"lIyGqVBJygUHHQ4ZoHyAc8INULSr1B4WnuCajei13QINe7U3SH\"\n",
        "access_token = \"549909021-ksoN2E4V4yAlhAPa5EUuItuiQhSXyIKFEvCHLqMv\"\n",
        "access_token_secret =\"JplD62xq9UPnlQ0NFekGINJZHO1nEpfmw8Myiyl6PyaXS\""
      ],
      "id": "sealed-colon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "breeding-ireland"
      },
      "source": [
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)"
      ],
      "id": "breeding-ireland",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "greenhouse-thunder"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Available Locations\n",
        "    available_loc = api.trends_available()\n",
        "    # writing a JSON file that has the available trends around the world\n",
        "    with open(\"available_locs_for_trend.json\",\"w\") as wp:\n",
        "        wp.write(json.dumps(available_loc, indent=1))\n",
        "\n",
        "    # Trends for Specific Country\n",
        "    loc = 'Colombia'\n",
        "    #loc = sys.argv[1]     # location as argument variable \n",
        "    g = geocoder.osm(loc) # getting object that has location's latitude and longitude\n",
        "\n",
        "    closest_loc = api.trends_closest(g.lat, g.lng)\n",
        "    #trends = api.trends_place(closest_loc[0]['woeid'])\n",
        "    trends = api.trends_place(id = 23424787)\n",
        "    # writing a JSON file that has the latest trends for that location\n",
        "    #with open(\"twitter_{}_trend.json\".format(loc),\"w\") as wp:\n",
        "        #wp.write(json.dumps(trends[0]['trends'], indent=1))\n",
        "    #Create DataFrame and write it to excel file\n",
        "    pd_trend = pd.DataFrame(trends[0]['trends'])\n",
        "    pd_trend['trend']=pd_trend.name\n",
        "    #pd_trend.sort_values(by=['tweet_volume'],ascending = False).to_excel(\"twitter_{}_trend_{date:%Y-%m-%d_%H_%M_%S}.xlsx\".format(loc,date=datetime.now()),index = False)\n",
        "    #pd_trend=pd_trend.sort_values(by=['tweet_volume'],ascending = False,ignore_index =True)\n",
        "    pd_trend['index'] = pd_trend.index+1\n",
        "    pd_trend = pd_trend[['index','trend','tweet_volume']]\n",
        "    pd_trend.to_excel(\"twitter_colombia_trend.xlsx\",index = False)\n",
        "    \n",
        "\n",
        "\n"
      ],
      "id": "greenhouse-thunder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "environmental-jacket"
      },
      "source": [
        "def get_woeid(place):\n",
        "    '''Get woeid by location'''\n",
        "    try:\n",
        "        trends = api.trends_available()\n",
        "        for val in trends:\n",
        "            if (val['name'].lower() == place.lower()):\n",
        "                return(val['woeid']) \n",
        "        print('Location Not Found')\n",
        "    except Exception as e:\n",
        "        print('Exception:',e)\n",
        "        return(0)\n",
        "      "
      ],
      "id": "environmental-jacket",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prerequisite-family"
      },
      "source": [
        "def get_trends(place):\n",
        "    #woeid colombia = 23424787\n",
        "    col_trends = api.trends_place(id =get_woeid(place))\n",
        "    trends = []\n",
        "    for trend in col_trends[0]['trends']:  \n",
        "        trends.append((trend['name'], trend['tweet_volume']))\n",
        "    pd_trends = pd.DataFrame(trends,columns = ['trend','tweet_volume'])\n",
        "    #pd_trends[~pd_trends['trend'].isin(FilterList)]\n",
        "    pd_trends.reset_index(inplace = True)\n",
        "    pd_trends['index'] = pd_trends.index+1\n",
        "    pd_trends = pd_trends[['index','trend','tweet_volume']]\n",
        "    pd_trends.to_excel(\"twitter_colombia_trend.xlsx\",index = False)"
      ],
      "id": "prerequisite-family",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irish-exhaust"
      },
      "source": [
        "get_trends('Colombia')"
      ],
      "id": "irish-exhaust",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clean-europe",
        "outputId": "8edf3f0a-9f90-4920-f186-b4e3cbd634bc"
      },
      "source": [
        "data_trend = pd.read_excel(\"twitter_colombia_trend.xlsx\")\n",
        "data_trend"
      ],
      "id": "clean-europe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>trend</th>\n",
              "      <th>tweet_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>#ParoNacional19M</td>\n",
              "      <td>117494.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Marta Luc√≠a Ram√≠rez</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>#ReformaALaSalud</td>\n",
              "      <td>20334.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Colmenares</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Canciller</td>\n",
              "      <td>15649.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Laura Moreno</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Enzo P√©rez</td>\n",
              "      <td>50346.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Ley 100</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>#SaqueLargoWIN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>#LaJuventudNecesita</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Sara</td>\n",
              "      <td>162139.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>Friends</td>\n",
              "      <td>1026471.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Nieto</td>\n",
              "      <td>18435.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>Juventus</td>\n",
              "      <td>72232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>Atalanta</td>\n",
              "      <td>45639.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>#UribeGolpista</td>\n",
              "      <td>46154.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>Vicepresidente</td>\n",
              "      <td>14471.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>Vargas Lleras</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>Cambio Radical</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>Hundimos</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>Copa Italia</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>Mar√≠a Camila</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>Juan Guillermo Cuadrado</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>Buenaventura</td>\n",
              "      <td>10201.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>Santa Fe</td>\n",
              "      <td>30864.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>Pirlo</td>\n",
              "      <td>31778.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>Romero</td>\n",
              "      <td>23673.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>VIVA EL PARO NACIONAL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>Ramos</td>\n",
              "      <td>23041.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>Guatemala</td>\n",
              "      <td>22228.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>Oportunista</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>Muriel</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>Cansado</td>\n",
              "      <td>27233.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>Congreso de la Rep√∫blica</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>Senado y C√°mara</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>36</td>\n",
              "      <td>Zapata</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>37</td>\n",
              "      <td>Everton</td>\n",
              "      <td>28454.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>38</td>\n",
              "      <td>Benedetti</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>BLINKS FINAL COUNTDOWN</td>\n",
              "      <td>1190446.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>40</td>\n",
              "      <td>James Rodr√≠guez</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>41</td>\n",
              "      <td>Facebook Live</td>\n",
              "      <td>37286.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>42</td>\n",
              "      <td>Ad Hoc</td>\n",
              "      <td>24796.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>43</td>\n",
              "      <td>Bitcoin</td>\n",
              "      <td>764071.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>44</td>\n",
              "      <td>#AvantelWomLaMismaVaina</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>45</td>\n",
              "      <td>#YoApoyoAQuintero</td>\n",
              "      <td>18913.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>46</td>\n",
              "      <td>#NosEsperanEnCasa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>47</td>\n",
              "      <td>#19Mayo</td>\n",
              "      <td>19199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>48</td>\n",
              "      <td>#PelaezdeFranciscoenLaW</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>#YoProtejoMiPa√≠s</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>50</td>\n",
              "      <td>#PrimeraLinea</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index                     trend  tweet_volume\n",
              "0       1          #ParoNacional19M      117494.0\n",
              "1       2       Marta Luc√≠a Ram√≠rez           NaN\n",
              "2       3          #ReformaALaSalud       20334.0\n",
              "3       4                Colmenares           NaN\n",
              "4       5                 Canciller       15649.0\n",
              "5       6              Laura Moreno           NaN\n",
              "6       7                Enzo P√©rez       50346.0\n",
              "7       8                   Ley 100           NaN\n",
              "8       9            #SaqueLargoWIN           NaN\n",
              "9      10       #LaJuventudNecesita           NaN\n",
              "10     11                      Sara      162139.0\n",
              "11     12                   Friends     1026471.0\n",
              "12     13                     Nieto       18435.0\n",
              "13     14                  Juventus       72232.0\n",
              "14     15                  Atalanta       45639.0\n",
              "15     16            #UribeGolpista       46154.0\n",
              "16     17            Vicepresidente       14471.0\n",
              "17     18             Vargas Lleras           NaN\n",
              "18     19            Cambio Radical           NaN\n",
              "19     20                  Hundimos           NaN\n",
              "20     21               Copa Italia           NaN\n",
              "21     22              Mar√≠a Camila           NaN\n",
              "22     23   Juan Guillermo Cuadrado           NaN\n",
              "23     24              Buenaventura       10201.0\n",
              "24     25                  Santa Fe       30864.0\n",
              "25     26                     Pirlo       31778.0\n",
              "26     27                    Romero       23673.0\n",
              "27     28     VIVA EL PARO NACIONAL           NaN\n",
              "28     29                     Ramos       23041.0\n",
              "29     30                 Guatemala       22228.0\n",
              "30     31               Oportunista           NaN\n",
              "31     32                    Muriel           NaN\n",
              "32     33                   Cansado       27233.0\n",
              "33     34  Congreso de la Rep√∫blica           NaN\n",
              "34     35           Senado y C√°mara           NaN\n",
              "35     36                    Zapata           NaN\n",
              "36     37                   Everton       28454.0\n",
              "37     38                 Benedetti           NaN\n",
              "38     39    BLINKS FINAL COUNTDOWN     1190446.0\n",
              "39     40           James Rodr√≠guez           NaN\n",
              "40     41             Facebook Live       37286.0\n",
              "41     42                    Ad Hoc       24796.0\n",
              "42     43                   Bitcoin      764071.0\n",
              "43     44   #AvantelWomLaMismaVaina           NaN\n",
              "44     45         #YoApoyoAQuintero       18913.0\n",
              "45     46         #NosEsperanEnCasa           NaN\n",
              "46     47                   #19Mayo       19199.0\n",
              "47     48   #PelaezdeFranciscoenLaW           NaN\n",
              "48     49          #YoProtejoMiPa√≠s           NaN\n",
              "49     50             #PrimeraLinea           NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accurate-store"
      },
      "source": [
        "def scraptweets(search_words, date_since, numTweets, numRuns):\n",
        "    \n",
        "    # Define a for-loop to generate tweets at regular intervals\n",
        "    # We cannot make large API call in one go. Hence, let's try T times\n",
        "    \n",
        "    # Define a pandas dataframe to store the date:\n",
        "    db_tweets = pd.DataFrame(columns = ['username', 'acctdesc', 'location', 'following',\n",
        "                                        'followers', 'totaltweets', 'usercreatedts', 'tweetcreatedts',\n",
        "                                        'retweetcount', 'text', 'hashtags']\n",
        "                                )\n",
        "    program_start = time.time()\n",
        "    for i in range(0, numRuns):\n",
        "        # We will time how long it takes to scrape tweets for each run:\n",
        "        start_run = time.time()\n",
        "        \n",
        "        # Collect tweets using the Cursor object\n",
        "        # .Cursor() returns an object that you can iterate or loop over to access the data collected.\n",
        "        # Each item in the iterator has various attributes that you can access to get information about each tweet\n",
        "        tweets = tw.Cursor(api.search, q=search_words, since=date_since,lang = 'es', tweet_mode='extended').items(numTweets)\n",
        "# Store these tweets into a python list\n",
        "        tweet_list = [tweet for tweet in tweets]\n",
        "# Obtain the following info (methods to call them out):\n",
        "        # user.screen_name - twitter handle\n",
        "        # user.description - description of account\n",
        "        # user.location - where is he tweeting from\n",
        "        # user.friends_count - no. of other users that user is following (following)\n",
        "        # user.followers_count - no. of other users who are following this user (followers)\n",
        "        # user.statuses_count - total tweets by user\n",
        "        # user.created_at - when the user account was created\n",
        "        # created_at - when the tweet was created\n",
        "        # retweet_count - no. of retweets\n",
        "        # (deprecated) user.favourites_count - probably total no. of tweets that is favourited by user\n",
        "        # retweeted_status.full_text - full text of the tweet\n",
        "        # tweet.entities['hashtags'] - hashtags in the tweet\n",
        "# Begin scraping the tweets individually:\n",
        "        noTweets = 0\n",
        "        for tweet in tweet_list:\n",
        "# Pull the values\n",
        "            username = tweet.user.screen_name\n",
        "            acctdesc = tweet.user.description\n",
        "            location = tweet.user.location\n",
        "            following = tweet.user.friends_count\n",
        "            followers = tweet.user.followers_count\n",
        "            totaltweets = tweet.user.statuses_count\n",
        "            usercreatedts = tweet.user.created_at\n",
        "            tweetcreatedts = tweet.created_at\n",
        "            retweetcount = tweet.retweet_count\n",
        "            hashtags = tweet.entities['hashtags']\n",
        "            try:\n",
        "                text = tweet.retweeted_status.full_text\n",
        "            except AttributeError:  # Not a Retweet\n",
        "                text = tweet.full_text\n",
        "# Add the 11 variables to the empty list - ith_tweet:\n",
        "            ith_tweet = [username, acctdesc, location, following, followers, totaltweets,\n",
        "                         usercreatedts, tweetcreatedts, retweetcount, text, hashtags]\n",
        "# Append to dataframe - db_tweets\n",
        "            db_tweets.loc[len(db_tweets)] = ith_tweet\n",
        "# increase counter - noTweets  \n",
        "            noTweets += 1\n",
        "        \n",
        "# Run ended:\n",
        "    end_run = time.time()\n",
        "    duration_run = round((end_run-start_run)/60, 2)\n",
        "\n",
        "    print('no. of tweets scraped for run {} is {}'.format(i + 1, noTweets))\n",
        "    print('time take for {} run to complete is {} mins'.format(i+1, duration_run))\n",
        "\n",
        "    time.sleep(0) #15 minute sleep time (920)\n",
        "# Once all runs have completed, save them to a single csv file:\n",
        "    from datetime import datetime\n",
        "\n",
        "    # Obtain timestamp in a readable format\n",
        "    to_csv_timestamp = datetime.today().strftime('%Y%m%d_%H%M%S')\n",
        "# Define working path and filename\n",
        "    path = os.getcwd()\n",
        "    filename = path + to_csv_timestamp + search_words+'_TT.csv'\n",
        "# Store dataframe in csv with creation date timestamp\n",
        "    db_tweets.to_csv(filename, index = False)\n",
        "\n",
        "    program_end = time.time()\n",
        "    print('Scraping has completed!')\n",
        "    print('Total time taken to scrap is {} minutes.'.format(round(program_end - program_start)/60, 2))"
      ],
      "id": "accurate-store",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impressed-truth",
        "outputId": "cb4bedc0-8226-4162-f84b-5f926c10e1b4"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#paronacional\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 1000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "impressed-truth",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 1000\n",
            "time take for 1 run to complete is 1.08 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 1.0833333333333333 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "parental-invite",
        "outputId": "213cf39b-fc35-4a0b-c267-c09a0dba59ac"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#jamesrodriguez\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "parental-invite",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 57\n",
            "time take for 1 run to complete is 0.06 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 0.06666666666666667 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chubby-capture",
        "outputId": "0ea37b0e-8cbb-4342-98fd-790344c00e16"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#barcelona\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "chubby-capture",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 0\n",
            "time take for 1 run to complete is 0.01 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 0.0 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rocky-wilderness",
        "outputId": "013e8630-38b5-4f28-ed86-0a20b444f429"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#seleccioncolombia\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "rocky-wilderness",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 195\n",
            "time take for 1 run to complete is 0.17 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 0.16666666666666666 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floppy-century",
        "outputId": "b7ec2009-6a08-454e-88c6-01ab1f59417d"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#bitcoin\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "floppy-century",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 2.35 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 2.35 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "parental-norman",
        "outputId": "73ae0df0-5e30-4216-dd75-8a5a2285fc49"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#ivanduque\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "parental-norman",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 14.39 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 14.4 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "healthy-institute",
        "outputId": "e8ffc93e-c049-47d2-b535-57ca70c3e8d3"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#felizviernes\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "healthy-institute",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 15.58 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 15.583333333333334 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lasting-illustration",
        "outputId": "ce19af52-4e81-45fa-9ce8-d840b5e235a9"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#felizlunes\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "lasting-illustration",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 14.62 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 14.616666666666667 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trained-shore",
        "outputId": "1910f36c-e534-43aa-fb51-b4cee69715cd"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#copalibertadores\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "trained-shore",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 14.55 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 14.55 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "desperate-ambassador",
        "outputId": "6dccf8a2-8d8e-4c8b-c2f2-a7bf4849afd9"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#adhoc\" \n",
        "date_since = \"2021-5-19\"\n",
        "numTweets = 1000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "desperate-ambassador",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 15\n",
            "time take for 1 run to complete is 0.04 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 0.03333333333333333 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auburn-leisure",
        "outputId": "75bf90cb-a2f9-4f87-9d94-bf736eb85f8d"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"#paronacional19M\" \n",
        "date_since = \"2021-5-05\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "auburn-leisure",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 2.61 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 2.6166666666666667 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "marked-yeast",
        "outputId": "9a0ac55d-a568-492a-be34-e71a49007f02"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"juan guillermo cuadrado\" \n",
        "date_since = \"2021-5-19\"\n",
        "numTweets = 1000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "marked-yeast",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 359\n",
            "time take for 1 run to complete is 0.4 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 0.4 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "corrected-leader",
        "outputId": "d832cbf5-6cf1-4ac1-dc22-9fbb0fd352aa"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"copaamerica\" \n",
        "date_since = \"2021-5-19\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "corrected-leader",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 2.13 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 2.1333333333333333 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "manufactured-disco",
        "outputId": "bbab1f04-8e46-41cc-9cec-4da893eef2c1"
      },
      "source": [
        "# Initialise these variables:\n",
        "search_words = \"eurocopa\" \n",
        "date_since = \"2021-5-19\"\n",
        "numTweets = 2000\n",
        "numRuns = 1\n",
        "# Call the function scraptweets\n",
        "scraptweets(search_words, date_since, numTweets, numRuns)"
      ],
      "id": "manufactured-disco",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 16.33 mins\n",
            "Scraping has completed!\n",
            "Total time taken to scrap is 16.35 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "outstanding-spanking",
        "outputId": "a4f51f1c-a156-40a9-ae56-70597075ddff"
      },
      "source": [
        "paronacional = pd.read_csv('../Twitter_exc20210519_191812#paronacional_TT.csv')\n",
        "paronacional\n",
        "\n"
      ],
      "id": "outstanding-spanking",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>acctdesc</th>\n",
              "      <th>location</th>\n",
              "      <th>following</th>\n",
              "      <th>followers</th>\n",
              "      <th>totaltweets</th>\n",
              "      <th>usercreatedts</th>\n",
              "      <th>tweetcreatedts</th>\n",
              "      <th>retweetcount</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>luisaDavilaSan1</td>\n",
              "      <td>Colombiana\\n17 years \\nARMY- BLINK</td>\n",
              "      <td>COLOMBIA</td>\n",
              "      <td>120</td>\n",
              "      <td>3</td>\n",
              "      <td>1116</td>\n",
              "      <td>2021-02-24 02:39:26</td>\n",
              "      <td>2021-05-20 00:17:05</td>\n",
              "      <td>1</td>\n",
              "      <td>CON LA POLIC√çA Y EL ESMAD NO HAY CASO. NO ESCU...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fotos_Ecuador</td>\n",
              "      <td>Mostrando nuestro hermoso pa√≠s al mundo.</td>\n",
              "      <td>Ecuador</td>\n",
              "      <td>847</td>\n",
              "      <td>299</td>\n",
              "      <td>6508</td>\n",
              "      <td>2016-09-21 05:49:07</td>\n",
              "      <td>2021-05-20 00:17:04</td>\n",
              "      <td>2</td>\n",
              "      <td>#ParoNacional\\nCali\\nLa Loma de la Dignidad en...</td>\n",
              "      <td>[{'text': 'ParoNacional', 'indices': [18, 31]}...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DiegoA3110</td>\n",
              "      <td>‚ù£Ô∏è. Antiuribista.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1149</td>\n",
              "      <td>2368</td>\n",
              "      <td>44948</td>\n",
              "      <td>2018-09-02 03:23:38</td>\n",
              "      <td>2021-05-20 00:17:04</td>\n",
              "      <td>2</td>\n",
              "      <td>#ParoNacional\\nCali\\nLa Loma de la Dignidad en...</td>\n",
              "      <td>[{'text': 'ParoNacional', 'indices': [18, 31]}...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OscarMonroy</td>\n",
              "      <td>Administrador de Empresas</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1112</td>\n",
              "      <td>244</td>\n",
              "      <td>37939</td>\n",
              "      <td>2009-08-25 18:59:37</td>\n",
              "      <td>2021-05-20 00:17:02</td>\n",
              "      <td>798</td>\n",
              "      <td>#Cali Siguen llenando de vida la Loma de La Di...</td>\n",
              "      <td>[{'text': 'Cali', 'indices': [20, 25]}, {'text...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rafalatino</td>\n",
              "      <td>iconoclasta,literato por afici√≥n,creativo por ...</td>\n",
              "      <td>Avenida El Cerro Caracas</td>\n",
              "      <td>1551</td>\n",
              "      <td>818</td>\n",
              "      <td>117805</td>\n",
              "      <td>2010-05-08 15:25:05</td>\n",
              "      <td>2021-05-20 00:17:01</td>\n",
              "      <td>5</td>\n",
              "      <td>#19May #Colombia \\n#Bogot√° Contin√∫an llegando ...</td>\n",
              "      <td>[{'text': '19May', 'indices': [15, 21]}, {'tex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>BedoyaEsLuis1</td>\n",
              "      <td>Conocimientos en la fe de la raz√≥n de la human...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2589</td>\n",
              "      <td>827</td>\n",
              "      <td>2109</td>\n",
              "      <td>2020-03-31 23:28:58</td>\n",
              "      <td>2021-05-19 23:59:27</td>\n",
              "      <td>11</td>\n",
              "      <td>A prop√≥sito de los saqueos y robos hoy en #Bue...</td>\n",
              "      <td>[{'text': 'Buenventura', 'indices': [61, 73]}]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Ruben0628</td>\n",
              "      <td>Ing. Administrador. Buen lector, HIncha del ve...</td>\n",
              "      <td>Medell√≠n</td>\n",
              "      <td>818</td>\n",
              "      <td>409</td>\n",
              "      <td>124266</td>\n",
              "      <td>2011-08-06 19:30:40</td>\n",
              "      <td>2021-05-19 23:59:21</td>\n",
              "      <td>6</td>\n",
              "      <td>Bonito gesto hoy en Medell√≠nü•∞. Esto es lo que ...</td>\n",
              "      <td>[{'text': 'ParoNacional19M', 'indices': [109, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>piedrahitangela</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Colombia</td>\n",
              "      <td>1025</td>\n",
              "      <td>24354</td>\n",
              "      <td>96841</td>\n",
              "      <td>2011-06-29 23:26:47</td>\n",
              "      <td>2021-05-19 23:59:21</td>\n",
              "      <td>385</td>\n",
              "      <td>Cali dice Viva el paro nacional!!\\n#19Mayo #Pa...</td>\n",
              "      <td>[{'text': '19Mayo', 'indices': [48, 55]}, {'te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>colombiamarchas</td>\n",
              "      <td>Cuenta oficial de Colombia Marcha, medios de c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50</td>\n",
              "      <td>14</td>\n",
              "      <td>509</td>\n",
              "      <td>2021-05-13 05:31:48</td>\n",
              "      <td>2021-05-19 23:59:20</td>\n",
              "      <td>11</td>\n",
              "      <td>#ParoNacional #19Mayo #ParoNacionalIndefinido ...</td>\n",
              "      <td>[{'text': 'ParoNacional', 'indices': [19, 32]}...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>leon1078</td>\n",
              "      <td>No soy de izquierda ni de derecha... ya que so...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>141</td>\n",
              "      <td>99</td>\n",
              "      <td>8724</td>\n",
              "      <td>2011-02-16 22:57:03</td>\n",
              "      <td>2021-05-19 23:59:19</td>\n",
              "      <td>192</td>\n",
              "      <td>#ParoNacional \\nBogot√° portal Am√©ricas https:/...</td>\n",
              "      <td>[{'text': 'ParoNacional', 'indices': [18, 31]}]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows √ó 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            username                                           acctdesc  \\\n",
              "0    luisaDavilaSan1                 Colombiana\\n17 years \\nARMY- BLINK   \n",
              "1      Fotos_Ecuador           Mostrando nuestro hermoso pa√≠s al mundo.   \n",
              "2         DiegoA3110                                  ‚ù£Ô∏è. Antiuribista.   \n",
              "3        OscarMonroy                          Administrador de Empresas   \n",
              "4         rafalatino  iconoclasta,literato por afici√≥n,creativo por ...   \n",
              "..               ...                                                ...   \n",
              "995    BedoyaEsLuis1  Conocimientos en la fe de la raz√≥n de la human...   \n",
              "996        Ruben0628  Ing. Administrador. Buen lector, HIncha del ve...   \n",
              "997  piedrahitangela                                                NaN   \n",
              "998  colombiamarchas  Cuenta oficial de Colombia Marcha, medios de c...   \n",
              "999         leon1078  No soy de izquierda ni de derecha... ya que so...   \n",
              "\n",
              "                      location  following  followers  totaltweets  \\\n",
              "0                     COLOMBIA        120          3         1116   \n",
              "1                      Ecuador        847        299         6508   \n",
              "2                          NaN       1149       2368        44948   \n",
              "3                          NaN       1112        244        37939   \n",
              "4     Avenida El Cerro Caracas       1551        818       117805   \n",
              "..                         ...        ...        ...          ...   \n",
              "995                        NaN       2589        827         2109   \n",
              "996                   Medell√≠n        818        409       124266   \n",
              "997                   Colombia       1025      24354        96841   \n",
              "998                        NaN         50         14          509   \n",
              "999                        NaN        141         99         8724   \n",
              "\n",
              "           usercreatedts       tweetcreatedts  retweetcount  \\\n",
              "0    2021-02-24 02:39:26  2021-05-20 00:17:05             1   \n",
              "1    2016-09-21 05:49:07  2021-05-20 00:17:04             2   \n",
              "2    2018-09-02 03:23:38  2021-05-20 00:17:04             2   \n",
              "3    2009-08-25 18:59:37  2021-05-20 00:17:02           798   \n",
              "4    2010-05-08 15:25:05  2021-05-20 00:17:01             5   \n",
              "..                   ...                  ...           ...   \n",
              "995  2020-03-31 23:28:58  2021-05-19 23:59:27            11   \n",
              "996  2011-08-06 19:30:40  2021-05-19 23:59:21             6   \n",
              "997  2011-06-29 23:26:47  2021-05-19 23:59:21           385   \n",
              "998  2021-05-13 05:31:48  2021-05-19 23:59:20            11   \n",
              "999  2011-02-16 22:57:03  2021-05-19 23:59:19           192   \n",
              "\n",
              "                                                  text  \\\n",
              "0    CON LA POLIC√çA Y EL ESMAD NO HAY CASO. NO ESCU...   \n",
              "1    #ParoNacional\\nCali\\nLa Loma de la Dignidad en...   \n",
              "2    #ParoNacional\\nCali\\nLa Loma de la Dignidad en...   \n",
              "3    #Cali Siguen llenando de vida la Loma de La Di...   \n",
              "4    #19May #Colombia \\n#Bogot√° Contin√∫an llegando ...   \n",
              "..                                                 ...   \n",
              "995  A prop√≥sito de los saqueos y robos hoy en #Bue...   \n",
              "996  Bonito gesto hoy en Medell√≠nü•∞. Esto es lo que ...   \n",
              "997  Cali dice Viva el paro nacional!!\\n#19Mayo #Pa...   \n",
              "998  #ParoNacional #19Mayo #ParoNacionalIndefinido ...   \n",
              "999  #ParoNacional \\nBogot√° portal Am√©ricas https:/...   \n",
              "\n",
              "                                              hashtags  \n",
              "0                                                   []  \n",
              "1    [{'text': 'ParoNacional', 'indices': [18, 31]}...  \n",
              "2    [{'text': 'ParoNacional', 'indices': [18, 31]}...  \n",
              "3    [{'text': 'Cali', 'indices': [20, 25]}, {'text...  \n",
              "4    [{'text': '19May', 'indices': [15, 21]}, {'tex...  \n",
              "..                                                 ...  \n",
              "995     [{'text': 'Buenventura', 'indices': [61, 73]}]  \n",
              "996  [{'text': 'ParoNacional19M', 'indices': [109, ...  \n",
              "997  [{'text': '19Mayo', 'indices': [48, 55]}, {'te...  \n",
              "998  [{'text': 'ParoNacional', 'indices': [19, 32]}...  \n",
              "999    [{'text': 'ParoNacional', 'indices': [18, 31]}]  \n",
              "\n",
              "[1000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "developed-publisher"
      },
      "source": [
        "##GET Twitter DataFrames"
      ],
      "id": "developed-publisher",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extended-integer",
        "outputId": "a9684dc2-35f2-499e-8340-c15071738f7a"
      },
      "source": [
        "%pwd"
      ],
      "id": "extended-integer",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/Users/mac/Documents/Datasets/Twitter_exc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "administrative-firmware"
      },
      "source": [
        "paronacional = pd.read_csv('../Twitter_exc20210519_193127#paronacional_TT.csv')\n",
        "jamesrodriguez = pd.read_csv('../Twitter_exc20210519_193131#jamesrodriguez_TT.csv')\n",
        "barcelona = pd.read_csv('../Twitter_exc20210519_193132#barcelona_TT.csv')\n",
        "felizviernes = pd.read_csv('../Twitter_exc20210519_200402#felizviernes_TT.csv')\n",
        "felizlunes = pd.read_csv('../Twitter_exc20210519_201839#felizlunes_TT.csv')\n",
        "copalibertadores = pd.read_csv('../Twitter_exc20210519_203312#copalibertadores_TT.csv')\n",
        "adhoc = pd.read_csv('../Twitter_exc20210519_203314#adhoc_TT.csv')\n",
        "copaamerica = pd.read_csv('../Twitter_exc20210706_090037copaamerica_TT.csv')\n",
        "eurocopa = pd.read_csv('../Twitter_exc20210706_091658eurocopa_TT.csv')\n",
        "bitcoin = pd.read_csv('../Twitter_exc20210519_193403#bitcoin_TT.csv')\n",
        "ivanduque = pd.read_excel('/Users/mac/Downloads/drive-download-20210702T123910Z-001/DuqueDiariodata.xlsx')"
      ],
      "id": "administrative-firmware",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "living-anderson"
      },
      "source": [
        "paronacional_train = paronacional[['text']]\n",
        "jamesrodriguez_train = jamesrodriguez[['text']]\n",
        "barcelona_train=barcelona[['text']]\n",
        "felizviernes_train = felizviernes[['text']]\n",
        "felizlunes_train = felizlunes[['text']]\n",
        "copalibertadores_train=copalibertadores[['text']]\n",
        "adhoc_train = adhoc[['text']]\n",
        "copaamerica_train = copaamerica[['text']]\n",
        "eurocopa_train = eurocopa[['text']]\n",
        "bitcoin_train = bitcoin[['text']]\n",
        "ivanduque_train = ivanduque[['Tweet']]\n"
      ],
      "id": "living-anderson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "caroline-present",
        "outputId": "239de6ec-cc81-45e1-cf0f-126bb2a2aa8e"
      },
      "source": [
        "ivanduque_train.rename(columns = {'Tweet':'text'},inplace = True)"
      ],
      "id": "caroline-present",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/pandas/core/frame.py:4449: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "downtown-apache"
      },
      "source": [
        "ivanduque_train_short = ivanduque_train[:2000]"
      ],
      "id": "downtown-apache",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "french-destiny",
        "outputId": "f8d796ef-278a-4faa-be97-377b9258619f"
      },
      "source": [
        "paronacional_train['clasificacion'] = 'Pol√≠tica'\n",
        "jamesrodriguez_train['clasificacion'] = 'Deportes'\n",
        "barcelona_train['clasificacion'] = 'Deportes'\n",
        "felizviernes_train['clasificacion'] = 'Otros'\n",
        "felizlunes_train['clasificacion'] = 'Otros'\n",
        "copalibertadores_train['clasificacion'] = 'Deportes'\n",
        "adhoc_train['clasificacion'] = 'Pol√≠tica'\n",
        "copaamerica_train['clasificacion'] = 'Deportes'\n",
        "eurocopa_train['clasificacion'] = 'Deportes'\n",
        "bitcoin_train['clasificacion'] = 'Econom√≠a'\n",
        "ivanduque_train['clasificacion'] = 'Pol√≠tica'"
      ],
      "id": "french-destiny",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nearby-leadership",
        "outputId": "cd48df62-ba32-4e75-cae2-38838918a098"
      },
      "source": [
        "Consolidado = pd.DataFrame(columns =[['text','Clasificaci√≥n']])\n",
        "Consolidado = pd.concat([paronacional_train,\n",
        "           jamesrodriguez_train,\n",
        "           barcelona_train,\n",
        "           felizviernes_train,\n",
        "           felizlunes_train,\n",
        "           copalibertadores_train,\n",
        "           adhoc_train,\n",
        "           copaamerica_train,\n",
        "           ivanduque_train_short],\n",
        "          ignore_index = True)\n",
        "Consolidado\n"
      ],
      "id": "nearby-leadership",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clasificacion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>El #ParoNacional ya se tumb√≥\\n1. La reforma tr...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Otro logro del #ParoNacional Colombia pierde c...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Una ola de protesta vuelve a inundar #Colombia...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Una ola de protesta vuelve a inundar #Colombia...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alguien podr√≠a decirme que dice la arenga que ...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11069</th>\n",
              "      <td>D√≠a a d√≠a los contagios y las muertes siguen a...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11070</th>\n",
              "      <td>@AForeroM @ClaudiaLopez \"Lo que faltaba, bandi...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11071</th>\n",
              "      <td>RT @juan_alies: La mejor noticia que di√≥ @Ivan...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11072</th>\n",
              "      <td>@elespectador \"Lo que faltaba, bandidos #Prime...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11073</th>\n",
              "      <td>RT @AlexLopezMaya: EEUU condiciona recursos a ...</td>\n",
              "      <td>Pol√≠tica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11074 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text clasificacion\n",
              "0      El #ParoNacional ya se tumb√≥\\n1. La reforma tr...      Pol√≠tica\n",
              "1      Otro logro del #ParoNacional Colombia pierde c...      Pol√≠tica\n",
              "2      Una ola de protesta vuelve a inundar #Colombia...      Pol√≠tica\n",
              "3      Una ola de protesta vuelve a inundar #Colombia...      Pol√≠tica\n",
              "4      Alguien podr√≠a decirme que dice la arenga que ...      Pol√≠tica\n",
              "...                                                  ...           ...\n",
              "11069  D√≠a a d√≠a los contagios y las muertes siguen a...      Pol√≠tica\n",
              "11070  @AForeroM @ClaudiaLopez \"Lo que faltaba, bandi...      Pol√≠tica\n",
              "11071  RT @juan_alies: La mejor noticia que di√≥ @Ivan...      Pol√≠tica\n",
              "11072  @elespectador \"Lo que faltaba, bandidos #Prime...      Pol√≠tica\n",
              "11073  RT @AlexLopezMaya: EEUU condiciona recursos a ...      Pol√≠tica\n",
              "\n",
              "[11074 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raised-disabled"
      },
      "source": [
        "##PREPROCCESSING"
      ],
      "id": "raised-disabled",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sunrise-animal",
        "outputId": "ece644f9-c8b2-427b-8ae4-6a50663b9696"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = stopwords.words('spanish')\n",
        "\n",
        "import string\n",
        "alphabet_string = string.ascii_lowercase\n",
        "#Create a string of all lowercase letters\n",
        "\n",
        "alphabet_list = list(alphabet_string)\n",
        "#Create a list of all lowercase letters\n",
        "\n",
        "two_word_list = []\n",
        "for a in alphabet_list:\n",
        "    for i in range(len(alphabet_list)):\n",
        "        two_word_list.append(a+alphabet_list[i])"
      ],
      "id": "sunrise-animal",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brave-excuse",
        "outputId": "6a388db6-f6fe-4b0b-ebaf-70abb748c075"
      },
      "source": [
        "newstopwords = ['x','q','si','ser','d','as','pa','ud','usted','se√±or','seor']\n",
        "for i in range(len(two_word_list)):\n",
        "    newstopwords.append(two_word_list[i])\n",
        "for element in newstopwords:\n",
        "    stop_words.append(element)\n",
        "stop_words"
      ],
      "id": "brave-excuse",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de',\n",
              " 'la',\n",
              " 'que',\n",
              " 'el',\n",
              " 'en',\n",
              " 'y',\n",
              " 'a',\n",
              " 'los',\n",
              " 'del',\n",
              " 'se',\n",
              " 'las',\n",
              " 'por',\n",
              " 'un',\n",
              " 'para',\n",
              " 'con',\n",
              " 'no',\n",
              " 'una',\n",
              " 'su',\n",
              " 'al',\n",
              " 'lo',\n",
              " 'como',\n",
              " 'm√°s',\n",
              " 'pero',\n",
              " 'sus',\n",
              " 'le',\n",
              " 'ya',\n",
              " 'o',\n",
              " 'este',\n",
              " 's√≠',\n",
              " 'porque',\n",
              " 'esta',\n",
              " 'entre',\n",
              " 'cuando',\n",
              " 'muy',\n",
              " 'sin',\n",
              " 'sobre',\n",
              " 'tambi√©n',\n",
              " 'me',\n",
              " 'hasta',\n",
              " 'hay',\n",
              " 'donde',\n",
              " 'quien',\n",
              " 'desde',\n",
              " 'todo',\n",
              " 'nos',\n",
              " 'durante',\n",
              " 'todos',\n",
              " 'uno',\n",
              " 'les',\n",
              " 'ni',\n",
              " 'contra',\n",
              " 'otros',\n",
              " 'ese',\n",
              " 'eso',\n",
              " 'ante',\n",
              " 'ellos',\n",
              " 'e',\n",
              " 'esto',\n",
              " 'm√≠',\n",
              " 'antes',\n",
              " 'algunos',\n",
              " 'qu√©',\n",
              " 'unos',\n",
              " 'yo',\n",
              " 'otro',\n",
              " 'otras',\n",
              " 'otra',\n",
              " '√©l',\n",
              " 'tanto',\n",
              " 'esa',\n",
              " 'estos',\n",
              " 'mucho',\n",
              " 'quienes',\n",
              " 'nada',\n",
              " 'muchos',\n",
              " 'cual',\n",
              " 'poco',\n",
              " 'ella',\n",
              " 'estar',\n",
              " 'estas',\n",
              " 'algunas',\n",
              " 'algo',\n",
              " 'nosotros',\n",
              " 'mi',\n",
              " 'mis',\n",
              " 't√∫',\n",
              " 'te',\n",
              " 'ti',\n",
              " 'tu',\n",
              " 'tus',\n",
              " 'ellas',\n",
              " 'nosotras',\n",
              " 'vosotros',\n",
              " 'vosotras',\n",
              " 'os',\n",
              " 'm√≠o',\n",
              " 'm√≠a',\n",
              " 'm√≠os',\n",
              " 'm√≠as',\n",
              " 'tuyo',\n",
              " 'tuya',\n",
              " 'tuyos',\n",
              " 'tuyas',\n",
              " 'suyo',\n",
              " 'suya',\n",
              " 'suyos',\n",
              " 'suyas',\n",
              " 'nuestro',\n",
              " 'nuestra',\n",
              " 'nuestros',\n",
              " 'nuestras',\n",
              " 'vuestro',\n",
              " 'vuestra',\n",
              " 'vuestros',\n",
              " 'vuestras',\n",
              " 'esos',\n",
              " 'esas',\n",
              " 'estoy',\n",
              " 'est√°s',\n",
              " 'est√°',\n",
              " 'estamos',\n",
              " 'est√°is',\n",
              " 'est√°n',\n",
              " 'est√©',\n",
              " 'est√©s',\n",
              " 'estemos',\n",
              " 'est√©is',\n",
              " 'est√©n',\n",
              " 'estar√©',\n",
              " 'estar√°s',\n",
              " 'estar√°',\n",
              " 'estaremos',\n",
              " 'estar√©is',\n",
              " 'estar√°n',\n",
              " 'estar√≠a',\n",
              " 'estar√≠as',\n",
              " 'estar√≠amos',\n",
              " 'estar√≠ais',\n",
              " 'estar√≠an',\n",
              " 'estaba',\n",
              " 'estabas',\n",
              " 'est√°bamos',\n",
              " 'estabais',\n",
              " 'estaban',\n",
              " 'estuve',\n",
              " 'estuviste',\n",
              " 'estuvo',\n",
              " 'estuvimos',\n",
              " 'estuvisteis',\n",
              " 'estuvieron',\n",
              " 'estuviera',\n",
              " 'estuvieras',\n",
              " 'estuvi√©ramos',\n",
              " 'estuvierais',\n",
              " 'estuvieran',\n",
              " 'estuviese',\n",
              " 'estuvieses',\n",
              " 'estuvi√©semos',\n",
              " 'estuvieseis',\n",
              " 'estuviesen',\n",
              " 'estando',\n",
              " 'estado',\n",
              " 'estada',\n",
              " 'estados',\n",
              " 'estadas',\n",
              " 'estad',\n",
              " 'he',\n",
              " 'has',\n",
              " 'ha',\n",
              " 'hemos',\n",
              " 'hab√©is',\n",
              " 'han',\n",
              " 'haya',\n",
              " 'hayas',\n",
              " 'hayamos',\n",
              " 'hay√°is',\n",
              " 'hayan',\n",
              " 'habr√©',\n",
              " 'habr√°s',\n",
              " 'habr√°',\n",
              " 'habremos',\n",
              " 'habr√©is',\n",
              " 'habr√°n',\n",
              " 'habr√≠a',\n",
              " 'habr√≠as',\n",
              " 'habr√≠amos',\n",
              " 'habr√≠ais',\n",
              " 'habr√≠an',\n",
              " 'hab√≠a',\n",
              " 'hab√≠as',\n",
              " 'hab√≠amos',\n",
              " 'hab√≠ais',\n",
              " 'hab√≠an',\n",
              " 'hube',\n",
              " 'hubiste',\n",
              " 'hubo',\n",
              " 'hubimos',\n",
              " 'hubisteis',\n",
              " 'hubieron',\n",
              " 'hubiera',\n",
              " 'hubieras',\n",
              " 'hubi√©ramos',\n",
              " 'hubierais',\n",
              " 'hubieran',\n",
              " 'hubiese',\n",
              " 'hubieses',\n",
              " 'hubi√©semos',\n",
              " 'hubieseis',\n",
              " 'hubiesen',\n",
              " 'habiendo',\n",
              " 'habido',\n",
              " 'habida',\n",
              " 'habidos',\n",
              " 'habidas',\n",
              " 'soy',\n",
              " 'eres',\n",
              " 'es',\n",
              " 'somos',\n",
              " 'sois',\n",
              " 'son',\n",
              " 'sea',\n",
              " 'seas',\n",
              " 'seamos',\n",
              " 'se√°is',\n",
              " 'sean',\n",
              " 'ser√©',\n",
              " 'ser√°s',\n",
              " 'ser√°',\n",
              " 'seremos',\n",
              " 'ser√©is',\n",
              " 'ser√°n',\n",
              " 'ser√≠a',\n",
              " 'ser√≠as',\n",
              " 'ser√≠amos',\n",
              " 'ser√≠ais',\n",
              " 'ser√≠an',\n",
              " 'era',\n",
              " 'eras',\n",
              " '√©ramos',\n",
              " 'erais',\n",
              " 'eran',\n",
              " 'fui',\n",
              " 'fuiste',\n",
              " 'fue',\n",
              " 'fuimos',\n",
              " 'fuisteis',\n",
              " 'fueron',\n",
              " 'fuera',\n",
              " 'fueras',\n",
              " 'fu√©ramos',\n",
              " 'fuerais',\n",
              " 'fueran',\n",
              " 'fuese',\n",
              " 'fueses',\n",
              " 'fu√©semos',\n",
              " 'fueseis',\n",
              " 'fuesen',\n",
              " 'sintiendo',\n",
              " 'sentido',\n",
              " 'sentida',\n",
              " 'sentidos',\n",
              " 'sentidas',\n",
              " 'siente',\n",
              " 'sentid',\n",
              " 'tengo',\n",
              " 'tienes',\n",
              " 'tiene',\n",
              " 'tenemos',\n",
              " 'ten√©is',\n",
              " 'tienen',\n",
              " 'tenga',\n",
              " 'tengas',\n",
              " 'tengamos',\n",
              " 'teng√°is',\n",
              " 'tengan',\n",
              " 'tendr√©',\n",
              " 'tendr√°s',\n",
              " 'tendr√°',\n",
              " 'tendremos',\n",
              " 'tendr√©is',\n",
              " 'tendr√°n',\n",
              " 'tendr√≠a',\n",
              " 'tendr√≠as',\n",
              " 'tendr√≠amos',\n",
              " 'tendr√≠ais',\n",
              " 'tendr√≠an',\n",
              " 'ten√≠a',\n",
              " 'ten√≠as',\n",
              " 'ten√≠amos',\n",
              " 'ten√≠ais',\n",
              " 'ten√≠an',\n",
              " 'tuve',\n",
              " 'tuviste',\n",
              " 'tuvo',\n",
              " 'tuvimos',\n",
              " 'tuvisteis',\n",
              " 'tuvieron',\n",
              " 'tuviera',\n",
              " 'tuvieras',\n",
              " 'tuvi√©ramos',\n",
              " 'tuvierais',\n",
              " 'tuvieran',\n",
              " 'tuviese',\n",
              " 'tuvieses',\n",
              " 'tuvi√©semos',\n",
              " 'tuvieseis',\n",
              " 'tuviesen',\n",
              " 'teniendo',\n",
              " 'tenido',\n",
              " 'tenida',\n",
              " 'tenidos',\n",
              " 'tenidas',\n",
              " 'tened',\n",
              " 'x',\n",
              " 'q',\n",
              " 'si',\n",
              " 'ser',\n",
              " 'd',\n",
              " 'as',\n",
              " 'pa',\n",
              " 'ud',\n",
              " 'usted',\n",
              " 'se√±or',\n",
              " 'seor',\n",
              " 'aa',\n",
              " 'ab',\n",
              " 'ac',\n",
              " 'ad',\n",
              " 'ae',\n",
              " 'af',\n",
              " 'ag',\n",
              " 'ah',\n",
              " 'ai',\n",
              " 'aj',\n",
              " 'ak',\n",
              " 'al',\n",
              " 'am',\n",
              " 'an',\n",
              " 'ao',\n",
              " 'ap',\n",
              " 'aq',\n",
              " 'ar',\n",
              " 'as',\n",
              " 'at',\n",
              " 'au',\n",
              " 'av',\n",
              " 'aw',\n",
              " 'ax',\n",
              " 'ay',\n",
              " 'az',\n",
              " 'ba',\n",
              " 'bb',\n",
              " 'bc',\n",
              " 'bd',\n",
              " 'be',\n",
              " 'bf',\n",
              " 'bg',\n",
              " 'bh',\n",
              " 'bi',\n",
              " 'bj',\n",
              " 'bk',\n",
              " 'bl',\n",
              " 'bm',\n",
              " 'bn',\n",
              " 'bo',\n",
              " 'bp',\n",
              " 'bq',\n",
              " 'br',\n",
              " 'bs',\n",
              " 'bt',\n",
              " 'bu',\n",
              " 'bv',\n",
              " 'bw',\n",
              " 'bx',\n",
              " 'by',\n",
              " 'bz',\n",
              " 'ca',\n",
              " 'cb',\n",
              " 'cc',\n",
              " 'cd',\n",
              " 'ce',\n",
              " 'cf',\n",
              " 'cg',\n",
              " 'ch',\n",
              " 'ci',\n",
              " 'cj',\n",
              " 'ck',\n",
              " 'cl',\n",
              " 'cm',\n",
              " 'cn',\n",
              " 'co',\n",
              " 'cp',\n",
              " 'cq',\n",
              " 'cr',\n",
              " 'cs',\n",
              " 'ct',\n",
              " 'cu',\n",
              " 'cv',\n",
              " 'cw',\n",
              " 'cx',\n",
              " 'cy',\n",
              " 'cz',\n",
              " 'da',\n",
              " 'db',\n",
              " 'dc',\n",
              " 'dd',\n",
              " 'de',\n",
              " 'df',\n",
              " 'dg',\n",
              " 'dh',\n",
              " 'di',\n",
              " 'dj',\n",
              " 'dk',\n",
              " 'dl',\n",
              " 'dm',\n",
              " 'dn',\n",
              " 'do',\n",
              " 'dp',\n",
              " 'dq',\n",
              " 'dr',\n",
              " 'ds',\n",
              " 'dt',\n",
              " 'du',\n",
              " 'dv',\n",
              " 'dw',\n",
              " 'dx',\n",
              " 'dy',\n",
              " 'dz',\n",
              " 'ea',\n",
              " 'eb',\n",
              " 'ec',\n",
              " 'ed',\n",
              " 'ee',\n",
              " 'ef',\n",
              " 'eg',\n",
              " 'eh',\n",
              " 'ei',\n",
              " 'ej',\n",
              " 'ek',\n",
              " 'el',\n",
              " 'em',\n",
              " 'en',\n",
              " 'eo',\n",
              " 'ep',\n",
              " 'eq',\n",
              " 'er',\n",
              " 'es',\n",
              " 'et',\n",
              " 'eu',\n",
              " 'ev',\n",
              " 'ew',\n",
              " 'ex',\n",
              " 'ey',\n",
              " 'ez',\n",
              " 'fa',\n",
              " 'fb',\n",
              " 'fc',\n",
              " 'fd',\n",
              " 'fe',\n",
              " 'ff',\n",
              " 'fg',\n",
              " 'fh',\n",
              " 'fi',\n",
              " 'fj',\n",
              " 'fk',\n",
              " 'fl',\n",
              " 'fm',\n",
              " 'fn',\n",
              " 'fo',\n",
              " 'fp',\n",
              " 'fq',\n",
              " 'fr',\n",
              " 'fs',\n",
              " 'ft',\n",
              " 'fu',\n",
              " 'fv',\n",
              " 'fw',\n",
              " 'fx',\n",
              " 'fy',\n",
              " 'fz',\n",
              " 'ga',\n",
              " 'gb',\n",
              " 'gc',\n",
              " 'gd',\n",
              " 'ge',\n",
              " 'gf',\n",
              " 'gg',\n",
              " 'gh',\n",
              " 'gi',\n",
              " 'gj',\n",
              " 'gk',\n",
              " 'gl',\n",
              " 'gm',\n",
              " 'gn',\n",
              " 'go',\n",
              " 'gp',\n",
              " 'gq',\n",
              " 'gr',\n",
              " 'gs',\n",
              " 'gt',\n",
              " 'gu',\n",
              " 'gv',\n",
              " 'gw',\n",
              " 'gx',\n",
              " 'gy',\n",
              " 'gz',\n",
              " 'ha',\n",
              " 'hb',\n",
              " 'hc',\n",
              " 'hd',\n",
              " 'he',\n",
              " 'hf',\n",
              " 'hg',\n",
              " 'hh',\n",
              " 'hi',\n",
              " 'hj',\n",
              " 'hk',\n",
              " 'hl',\n",
              " 'hm',\n",
              " 'hn',\n",
              " 'ho',\n",
              " 'hp',\n",
              " 'hq',\n",
              " 'hr',\n",
              " 'hs',\n",
              " 'ht',\n",
              " 'hu',\n",
              " 'hv',\n",
              " 'hw',\n",
              " 'hx',\n",
              " 'hy',\n",
              " 'hz',\n",
              " 'ia',\n",
              " 'ib',\n",
              " 'ic',\n",
              " 'id',\n",
              " 'ie',\n",
              " 'if',\n",
              " 'ig',\n",
              " 'ih',\n",
              " 'ii',\n",
              " 'ij',\n",
              " 'ik',\n",
              " 'il',\n",
              " 'im',\n",
              " 'in',\n",
              " 'io',\n",
              " 'ip',\n",
              " 'iq',\n",
              " 'ir',\n",
              " 'is',\n",
              " 'it',\n",
              " 'iu',\n",
              " 'iv',\n",
              " 'iw',\n",
              " 'ix',\n",
              " 'iy',\n",
              " 'iz',\n",
              " 'ja',\n",
              " 'jb',\n",
              " 'jc',\n",
              " 'jd',\n",
              " 'je',\n",
              " 'jf',\n",
              " 'jg',\n",
              " 'jh',\n",
              " 'ji',\n",
              " 'jj',\n",
              " 'jk',\n",
              " 'jl',\n",
              " 'jm',\n",
              " 'jn',\n",
              " 'jo',\n",
              " 'jp',\n",
              " 'jq',\n",
              " 'jr',\n",
              " 'js',\n",
              " 'jt',\n",
              " 'ju',\n",
              " 'jv',\n",
              " 'jw',\n",
              " 'jx',\n",
              " 'jy',\n",
              " 'jz',\n",
              " 'ka',\n",
              " 'kb',\n",
              " 'kc',\n",
              " 'kd',\n",
              " 'ke',\n",
              " 'kf',\n",
              " 'kg',\n",
              " 'kh',\n",
              " 'ki',\n",
              " 'kj',\n",
              " 'kk',\n",
              " 'kl',\n",
              " 'km',\n",
              " 'kn',\n",
              " 'ko',\n",
              " 'kp',\n",
              " 'kq',\n",
              " 'kr',\n",
              " 'ks',\n",
              " 'kt',\n",
              " 'ku',\n",
              " 'kv',\n",
              " 'kw',\n",
              " 'kx',\n",
              " 'ky',\n",
              " 'kz',\n",
              " 'la',\n",
              " 'lb',\n",
              " 'lc',\n",
              " 'ld',\n",
              " 'le',\n",
              " 'lf',\n",
              " 'lg',\n",
              " 'lh',\n",
              " 'li',\n",
              " 'lj',\n",
              " 'lk',\n",
              " 'll',\n",
              " 'lm',\n",
              " 'ln',\n",
              " 'lo',\n",
              " 'lp',\n",
              " 'lq',\n",
              " 'lr',\n",
              " 'ls',\n",
              " 'lt',\n",
              " 'lu',\n",
              " 'lv',\n",
              " 'lw',\n",
              " 'lx',\n",
              " 'ly',\n",
              " 'lz',\n",
              " 'ma',\n",
              " 'mb',\n",
              " 'mc',\n",
              " 'md',\n",
              " 'me',\n",
              " 'mf',\n",
              " 'mg',\n",
              " 'mh',\n",
              " 'mi',\n",
              " 'mj',\n",
              " 'mk',\n",
              " 'ml',\n",
              " 'mm',\n",
              " 'mn',\n",
              " 'mo',\n",
              " 'mp',\n",
              " 'mq',\n",
              " 'mr',\n",
              " 'ms',\n",
              " 'mt',\n",
              " 'mu',\n",
              " 'mv',\n",
              " 'mw',\n",
              " 'mx',\n",
              " 'my',\n",
              " 'mz',\n",
              " 'na',\n",
              " 'nb',\n",
              " 'nc',\n",
              " 'nd',\n",
              " 'ne',\n",
              " 'nf',\n",
              " 'ng',\n",
              " 'nh',\n",
              " 'ni',\n",
              " 'nj',\n",
              " 'nk',\n",
              " 'nl',\n",
              " 'nm',\n",
              " 'nn',\n",
              " 'no',\n",
              " 'np',\n",
              " 'nq',\n",
              " 'nr',\n",
              " 'ns',\n",
              " 'nt',\n",
              " 'nu',\n",
              " 'nv',\n",
              " 'nw',\n",
              " 'nx',\n",
              " 'ny',\n",
              " 'nz',\n",
              " 'oa',\n",
              " 'ob',\n",
              " 'oc',\n",
              " 'od',\n",
              " 'oe',\n",
              " 'of',\n",
              " 'og',\n",
              " 'oh',\n",
              " 'oi',\n",
              " 'oj',\n",
              " 'ok',\n",
              " 'ol',\n",
              " 'om',\n",
              " 'on',\n",
              " 'oo',\n",
              " 'op',\n",
              " 'oq',\n",
              " 'or',\n",
              " 'os',\n",
              " 'ot',\n",
              " 'ou',\n",
              " 'ov',\n",
              " 'ow',\n",
              " 'ox',\n",
              " 'oy',\n",
              " 'oz',\n",
              " 'pa',\n",
              " 'pb',\n",
              " 'pc',\n",
              " 'pd',\n",
              " 'pe',\n",
              " 'pf',\n",
              " 'pg',\n",
              " 'ph',\n",
              " 'pi',\n",
              " 'pj',\n",
              " 'pk',\n",
              " 'pl',\n",
              " 'pm',\n",
              " 'pn',\n",
              " 'po',\n",
              " 'pp',\n",
              " 'pq',\n",
              " 'pr',\n",
              " 'ps',\n",
              " 'pt',\n",
              " 'pu',\n",
              " 'pv',\n",
              " 'pw',\n",
              " 'px',\n",
              " 'py',\n",
              " 'pz',\n",
              " 'qa',\n",
              " 'qb',\n",
              " 'qc',\n",
              " 'qd',\n",
              " 'qe',\n",
              " 'qf',\n",
              " 'qg',\n",
              " 'qh',\n",
              " 'qi',\n",
              " 'qj',\n",
              " 'qk',\n",
              " 'ql',\n",
              " 'qm',\n",
              " 'qn',\n",
              " 'qo',\n",
              " 'qp',\n",
              " 'qq',\n",
              " 'qr',\n",
              " 'qs',\n",
              " 'qt',\n",
              " 'qu',\n",
              " 'qv',\n",
              " 'qw',\n",
              " 'qx',\n",
              " 'qy',\n",
              " 'qz',\n",
              " 'ra',\n",
              " 'rb',\n",
              " 'rc',\n",
              " 'rd',\n",
              " 're',\n",
              " 'rf',\n",
              " 'rg',\n",
              " 'rh',\n",
              " 'ri',\n",
              " 'rj',\n",
              " 'rk',\n",
              " 'rl',\n",
              " 'rm',\n",
              " 'rn',\n",
              " 'ro',\n",
              " 'rp',\n",
              " 'rq',\n",
              " 'rr',\n",
              " 'rs',\n",
              " 'rt',\n",
              " 'ru',\n",
              " 'rv',\n",
              " 'rw',\n",
              " 'rx',\n",
              " 'ry',\n",
              " 'rz',\n",
              " 'sa',\n",
              " 'sb',\n",
              " 'sc',\n",
              " 'sd',\n",
              " 'se',\n",
              " 'sf',\n",
              " 'sg',\n",
              " 'sh',\n",
              " 'si',\n",
              " 'sj',\n",
              " 'sk',\n",
              " 'sl',\n",
              " 'sm',\n",
              " 'sn',\n",
              " 'so',\n",
              " 'sp',\n",
              " 'sq',\n",
              " 'sr',\n",
              " 'ss',\n",
              " 'st',\n",
              " 'su',\n",
              " 'sv',\n",
              " 'sw',\n",
              " 'sx',\n",
              " 'sy',\n",
              " 'sz',\n",
              " 'ta',\n",
              " 'tb',\n",
              " 'tc',\n",
              " 'td',\n",
              " 'te',\n",
              " 'tf',\n",
              " 'tg',\n",
              " 'th',\n",
              " 'ti',\n",
              " 'tj',\n",
              " 'tk',\n",
              " 'tl',\n",
              " 'tm',\n",
              " 'tn',\n",
              " 'to',\n",
              " 'tp',\n",
              " 'tq',\n",
              " 'tr',\n",
              " 'ts',\n",
              " 'tt',\n",
              " 'tu',\n",
              " 'tv',\n",
              " 'tw',\n",
              " 'tx',\n",
              " 'ty',\n",
              " 'tz',\n",
              " 'ua',\n",
              " 'ub',\n",
              " 'uc',\n",
              " 'ud',\n",
              " 'ue',\n",
              " 'uf',\n",
              " 'ug',\n",
              " 'uh',\n",
              " 'ui',\n",
              " 'uj',\n",
              " 'uk',\n",
              " 'ul',\n",
              " 'um',\n",
              " 'un',\n",
              " 'uo',\n",
              " 'up',\n",
              " 'uq',\n",
              " 'ur',\n",
              " 'us',\n",
              " 'ut',\n",
              " 'uu',\n",
              " 'uv',\n",
              " 'uw',\n",
              " 'ux',\n",
              " 'uy',\n",
              " 'uz',\n",
              " 'va',\n",
              " 'vb',\n",
              " 'vc',\n",
              " 'vd',\n",
              " 've',\n",
              " 'vf',\n",
              " 'vg',\n",
              " 'vh',\n",
              " 'vi',\n",
              " 'vj',\n",
              " 'vk',\n",
              " 'vl',\n",
              " 'vm',\n",
              " 'vn',\n",
              " 'vo',\n",
              " 'vp',\n",
              " 'vq',\n",
              " 'vr',\n",
              " 'vs',\n",
              " 'vt',\n",
              " 'vu',\n",
              " 'vv',\n",
              " 'vw',\n",
              " 'vx',\n",
              " 'vy',\n",
              " 'vz',\n",
              " 'wa',\n",
              " 'wb',\n",
              " 'wc',\n",
              " 'wd',\n",
              " 'we',\n",
              " 'wf',\n",
              " 'wg',\n",
              " 'wh',\n",
              " 'wi',\n",
              " 'wj',\n",
              " 'wk',\n",
              " 'wl',\n",
              " 'wm',\n",
              " 'wn',\n",
              " 'wo',\n",
              " 'wp',\n",
              " 'wq',\n",
              " 'wr',\n",
              " 'ws',\n",
              " 'wt',\n",
              " 'wu',\n",
              " 'wv',\n",
              " 'ww',\n",
              " 'wx',\n",
              " 'wy',\n",
              " 'wz',\n",
              " 'xa',\n",
              " 'xb',\n",
              " 'xc',\n",
              " 'xd',\n",
              " 'xe',\n",
              " 'xf',\n",
              " 'xg',\n",
              " 'xh',\n",
              " 'xi',\n",
              " 'xj',\n",
              " 'xk',\n",
              " 'xl',\n",
              " 'xm',\n",
              " 'xn',\n",
              " 'xo',\n",
              " 'xp',\n",
              " 'xq',\n",
              " 'xr',\n",
              " 'xs',\n",
              " 'xt',\n",
              " 'xu',\n",
              " 'xv',\n",
              " 'xw',\n",
              " 'xx',\n",
              " 'xy',\n",
              " 'xz',\n",
              " 'ya',\n",
              " 'yb',\n",
              " 'yc',\n",
              " 'yd',\n",
              " 'ye',\n",
              " 'yf',\n",
              " 'yg',\n",
              " 'yh',\n",
              " 'yi',\n",
              " 'yj',\n",
              " 'yk',\n",
              " 'yl',\n",
              " 'ym',\n",
              " 'yn',\n",
              " 'yo',\n",
              " 'yp',\n",
              " 'yq',\n",
              " 'yr',\n",
              " 'ys',\n",
              " 'yt',\n",
              " 'yu',\n",
              " 'yv',\n",
              " 'yw',\n",
              " 'yx',\n",
              " 'yy',\n",
              " 'yz',\n",
              " 'za',\n",
              " 'zb',\n",
              " 'zc',\n",
              " 'zd',\n",
              " 'ze',\n",
              " 'zf',\n",
              " 'zg',\n",
              " 'zh',\n",
              " 'zi',\n",
              " 'zj',\n",
              " 'zk',\n",
              " 'zl',\n",
              " 'zm',\n",
              " 'zn',\n",
              " 'zo',\n",
              " 'zp',\n",
              " 'zq',\n",
              " 'zr',\n",
              " 'zs',\n",
              " 'zt',\n",
              " 'zu',\n",
              " 'zv',\n",
              " 'zw',\n",
              " 'zx',\n",
              " 'zy',\n",
              " 'zz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "victorian-offense"
      },
      "source": [
        "def remove_url(txt):\n",
        "    \"\"\"Replace URLs found in a text string with nothing \n",
        "    (i.e. it will remove the URL from the string).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    txt : string\n",
        "        A text string that you want to parse and remove urls.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    The same txt string with url's removed.\n",
        "    \"\"\"\n",
        "\n",
        "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
      ],
      "id": "victorian-offense",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "popular-block"
      },
      "source": [
        "def remove_hash_ad_emojis(text):\n",
        "    return \" \".join(re.sub(\"(RT)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\"\", text).split())\n",
        "\n"
      ],
      "id": "popular-block",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "polished-purpose",
        "outputId": "a601d4e4-c7d0-4699-c180-ea192e3da5ca"
      },
      "source": [
        "Consolidado['text']"
      ],
      "id": "polished-purpose",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        El #ParoNacional ya se tumb√≥\\n1. La reforma tr...\n",
              "1        Otro logro del #ParoNacional Colombia pierde c...\n",
              "2        Una ola de protesta vuelve a inundar #Colombia...\n",
              "3        Una ola de protesta vuelve a inundar #Colombia...\n",
              "4        Alguien podr√≠a decirme que dice la arenga que ...\n",
              "                               ...                        \n",
              "11069    D√≠a a d√≠a los contagios y las muertes siguen a...\n",
              "11070    @AForeroM @ClaudiaLopez \"Lo que faltaba, bandi...\n",
              "11071    RT @juan_alies: La mejor noticia que di√≥ @Ivan...\n",
              "11072    @elespectador \"Lo que faltaba, bandidos #Prime...\n",
              "11073    RT @AlexLopezMaya: EEUU condiciona recursos a ...\n",
              "Name: text, Length: 11074, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mineral-struggle"
      },
      "source": [
        "Consolidado['text']=Consolidado['text'].apply(lambda x: remove_hash_ad_emojis(str(x)))"
      ],
      "id": "mineral-struggle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "closing-locking"
      },
      "source": [
        ""
      ],
      "id": "closing-locking",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "traditional-affair"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = Consolidado['text']\n",
        "y =Consolidado['clasificacion']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "id": "traditional-affair",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stopped-representative"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#tfidf = TfidfVectorizer(stop_words=stop_words)\n",
        "from sklearn.svm import LinearSVC\n",
        "clf_pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stop_words)),('clf',LinearSVC())])"
      ],
      "id": "stopped-representative",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "considered-treasurer",
        "outputId": "970dbcb1-698a-42e3-ee4b-3987178bb73d"
      },
      "source": [
        "clf_pipeline.fit(X_train,y_train)"
      ],
      "id": "considered-treasurer",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 TfidfVectorizer(stop_words=['de', 'la', 'que', 'el', 'en', 'y',\n",
              "                                             'a', 'los', 'del', 'se', 'las',\n",
              "                                             'por', 'un', 'para', 'con', 'no',\n",
              "                                             'una', 'su', 'al', 'lo', 'como',\n",
              "                                             'm√°s', 'pero', 'sus', 'le', 'ya',\n",
              "                                             'o', 'este', 's√≠', 'porque', ...])),\n",
              "                ('clf', LinearSVC())])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruled-groove"
      },
      "source": [
        "predictions = clf_pipeline.predict(X_test)"
      ],
      "id": "ruled-groove",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovely-review",
        "outputId": "6d5ad342-7865-41e2-a412-2f151d1c239a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "id": "lovely-review",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1284    6   17]\n",
            " [   0 1323   16]\n",
            " [   3   12  994]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conventional-monitor",
        "outputId": "502f6a6b-7d86-4cb0-e974-ca0aaf910adf"
      },
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "id": "conventional-monitor",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Deportes       1.00      0.98      0.99      1307\n",
            "       Otros       0.99      0.99      0.99      1339\n",
            "    Pol√≠tica       0.97      0.99      0.98      1009\n",
            "\n",
            "    accuracy                           0.99      3655\n",
            "   macro avg       0.98      0.99      0.98      3655\n",
            "weighted avg       0.99      0.99      0.99      3655\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "documentary-charlotte",
        "outputId": "77ee8a1f-43c5-4060-82fb-6dbcb8794a79"
      },
      "source": [
        "print(accuracy_score(y_test,predictions\n",
        "                    ))"
      ],
      "id": "documentary-charlotte",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9852257181942544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "macro-potato",
        "outputId": "6a3b1133-7eb5-4272-f838-3d4c0e4e9a81"
      },
      "source": [
        "X_test"
      ],
      "id": "macro-potato",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5579     Final 1TIndependienteSantaFe est tentado con p...\n",
              "6779     CopaLibertadores Libertadores RiverPlate Indep...\n",
              "8350     Me siento muy orgulloso de ser parte de esta s...\n",
              "7150     Una falta de respeto como le habla a todos los...\n",
              "7701     Me siento muy orgulloso de ser parte de esta s...\n",
              "                               ...                        \n",
              "2175     Con todo el respeto del mundo porque los sbado...\n",
              "10780    Hoy me quedo con esta frase del Dr comentando ...\n",
              "2540     BuenosDas y FelizViernes Quedan pocos minutos ...\n",
              "9711     tengo un pariente que es mamerto y siempre esc...\n",
              "4993     Hoy puede ser un buen da para que eches a vola...\n",
              "Name: text, Length: 3655, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advanced-lawsuit",
        "outputId": "a06f11cb-8d6d-446a-86d3-544471c23f6f"
      },
      "source": [
        "clf_pipeline.predict([''])[0]"
      ],
      "id": "advanced-lawsuit",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deportes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "secure-confidentiality"
      },
      "source": [
        "ivanduque_test = ivanduque_train[2000:5000]"
      ],
      "id": "secure-confidentiality",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leading-smoke",
        "outputId": "6dc90735-9e4e-4b82-bcf7-45abb5c49fce"
      },
      "source": [
        "ivanduque_test['prediccion']= ivanduque_test['text'].apply(lambda x:clf_pipeline.predict([x])[0])"
      ],
      "id": "leading-smoke",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/mac/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "median-yugoslavia",
        "outputId": "239a0d61-2778-4956-add1-c60f963ebffe"
      },
      "source": [
        "accuracy_score(ivanduque_test['clasificacion'],ivanduque_test['prediccion'])"
      ],
      "id": "median-yugoslavia",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9663333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conceptual-physiology"
      },
      "source": [
        "model = clf_pipeline"
      ],
      "id": "conceptual-physiology",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "integral-screw"
      },
      "source": [
        "##SAVING MODEL TO PICKLE"
      ],
      "id": "integral-screw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "animated-circulation",
        "outputId": "3cf4837a-aa41-4c02-a9b7-fb104ea8d97d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "filename = '/content/twitter_classifier_model_v1.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "id": "animated-circulation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6687f9d4f145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# save the model to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/twitter_classifier_model_v1.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# some time later...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "living-racing"
      },
      "source": [
        ""
      ],
      "id": "living-racing",
      "execution_count": null,
      "outputs": []
    }
  ]
}